{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ Sentiment Analyzer - Movie Review Classification\n",
    "\n",
    "This notebook demonstrates sentiment analysis using Natural Language Processing (NLP) and machine learning to classify movie reviews as positive or negative.\n",
    "\n",
    "**Author:** Shams Rupak  \n",
    "**GitHub:** https://github.com/ShamsRupak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Download NLTK Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "print(\"üì• Downloading required NLTK data...\")\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Define Text Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by cleaning, lowercasing, and removing stopwords.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and short words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Load and Prepare Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading movie reviews dataset...\")\n",
    "\n",
    "# Load positive and negative reviews\n",
    "positive_reviews = [(movie_reviews.raw(fileid), 'positive') \n",
    "                   for fileid in movie_reviews.fileids('pos')]\n",
    "negative_reviews = [(movie_reviews.raw(fileid), 'negative') \n",
    "                   for fileid in movie_reviews.fileids('neg')]\n",
    "\n",
    "# Combine and create DataFrame\n",
    "all_reviews = positive_reviews + negative_reviews\n",
    "df = pd.DataFrame(all_reviews, columns=['review', 'sentiment'])\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} reviews\")\n",
    "print(f\"\\nüìà Dataset distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualize Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "df['sentiment'].value_counts().plot(kind='bar', color=['#28a745', '#dc3545'])\n",
    "plt.title('Distribution of Movie Review Sentiments', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(df['sentiment'].value_counts()):\n",
    "    plt.text(i, v + 10, str(v), ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Preprocess Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Preprocessing text...\")\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Show sample of preprocessed text\n",
    "print(\"\\nüìù Sample preprocessed reviews:\")\n",
    "for i in range(2):\n",
    "    print(f\"\\n{df['sentiment'][i].upper()} Review:\")\n",
    "    print(f\"Original: {df['review'][i][:100]}...\")\n",
    "    print(f\"Processed: {df['processed_review'][i][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Create Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for positive and negative reviews\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Positive reviews word cloud\n",
    "positive_text = ' '.join(df[df['sentiment'] == 'positive']['processed_review'])\n",
    "positive_wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
    "                              colormap='Greens').generate(positive_text)\n",
    "\n",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')\n",
    "axes[0].set_title('Positive Reviews Word Cloud üòä', fontsize=16, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Negative reviews word cloud\n",
    "negative_text = ' '.join(df[df['sentiment'] == 'negative']['processed_review'])\n",
    "negative_wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
    "                              colormap='Reds').generate(negative_text)\n",
    "\n",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')\n",
    "axes[1].set_title('Negative Reviews Word Cloud üòû', fontsize=16, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Split Data and Convert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to binary (0 for negative, 1 for positive)\n",
    "df['label'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "# Split data\n",
    "X = df['processed_review']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÇÔ∏è Data split:\")\n",
    "print(f\"üìä Training samples: {len(X_train)}\")\n",
    "print(f\"üìä Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî§ Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ TF-IDF Feature dimensions: {X_train_tfidf.shape[1]}\")\n",
    "\n",
    "# Get feature names and their importance\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(f\"\\nüìù Sample features: {list(feature_names[:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nü§ñ Training {name}...\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name} Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "models_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in models_names]\n",
    "\n",
    "bars = plt.bar(models_names, accuracies, color=['#3498db', '#e74c3c'])\n",
    "plt.title('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim(0.8, 0.9)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002, \n",
    "             f'{acc:.2%}', ha='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Confusion Matrix for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_test, best_predictions, \n",
    "                          target_names=['Negative üòû', 'Positive üòä']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Interactive Sentiment Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, vectorizer):\n",
    "    \"\"\"Predict sentiment of a given text.\"\"\"\n",
    "    # Preprocess\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    # Transform to features\n",
    "    features = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Get prediction and probability\n",
    "    prediction = model.predict(features)[0]\n",
    "    probability = model.predict_proba(features)[0]\n",
    "    \n",
    "    sentiment = \"Positive üòä\" if prediction == 1 else \"Negative üòû\"\n",
    "    confidence = max(probability) * 100\n",
    "    \n",
    "    return sentiment, confidence\n",
    "\n",
    "# Test with sample reviews\n",
    "sample_reviews = [\n",
    "    \"This movie was absolutely fantastic! The acting was superb and the plot kept me engaged throughout.\",\n",
    "    \"Terrible movie. The plot made no sense and the acting was wooden. Complete waste of time.\",\n",
    "    \"The movie had some good moments but overall felt rushed and incomplete.\"\n",
    "]\n",
    "\n",
    "print(\"üé¨ SAMPLE PREDICTIONS\\n\" + \"=\"*50)\n",
    "\n",
    "for review in sample_reviews:\n",
    "    sentiment, confidence = predict_sentiment(review, best_model, tfidf_vectorizer)\n",
    "    print(f\"\\nüìù Review: {review}\")\n",
    "    print(f\"üé≠ Sentiment: {sentiment}\")\n",
    "    print(f\"üí™ Confidence: {confidence:.1f}%\")\n",
    "    \n",
    "    # Visual confidence bar\n",
    "    bar_length = 30\n",
    "    filled = int(bar_length * confidence / 100)\n",
    "    bar = \"‚ñà\" * filled + \"‚ñë\" * (bar_length - filled)\n",
    "    print(f\"üìä [{bar}] {confidence:.1f}%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for Logistic Regression\n",
    "if 'Logistic Regression' in results:\n",
    "    lr_model = results['Logistic Regression']['model']\n",
    "    coefficients = lr_model.coef_[0]\n",
    "    \n",
    "    # Get top positive and negative features\n",
    "    top_positive_idx = np.argsort(coefficients)[-20:]\n",
    "    top_negative_idx = np.argsort(coefficients)[:20]\n",
    "    \n",
    "    top_positive_features = [(feature_names[i], coefficients[i]) for i in top_positive_idx]\n",
    "    top_negative_features = [(feature_names[i], coefficients[i]) for i in top_negative_idx]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Positive features\n",
    "    positive_words, positive_scores = zip(*top_positive_features)\n",
    "    ax1.barh(positive_words, positive_scores, color='green')\n",
    "    ax1.set_title('Top Words for Positive Sentiment', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Coefficient Value')\n",
    "    \n",
    "    # Negative features\n",
    "    negative_words, negative_scores = zip(*top_negative_features)\n",
    "    ax2.barh(negative_words, negative_scores, color='red')\n",
    "    ax2.set_title('Top Words for Negative Sentiment', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Coefficient Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Your Turn - Try Your Own Review!\n",
    "\n",
    "Run the cell below and enter your own movie review to see the sentiment prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive input\n",
    "user_review = input(\"üí¨ Enter your movie review: \")\n",
    "\n",
    "if user_review:\n",
    "    sentiment, confidence = predict_sentiment(user_review, best_model, tfidf_vectorizer)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"üìä ANALYSIS RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üé≠ Sentiment: {sentiment}\")\n",
    "    print(f\"üí™ Confidence: {confidence:.1f}%\")\n",
    "    \n",
    "    # Visual confidence bar\n",
    "    bar_length = 30\n",
    "    filled = int(bar_length * confidence / 100)\n",
    "    bar = \"‚ñà\" * filled + \"‚ñë\" * (bar_length - filled)\n",
    "    print(f\"üìä [{bar}] {confidence:.1f}%\")\n",
    "    \n",
    "    if confidence > 90:\n",
    "        print(\"‚ú® Very confident prediction!\")\n",
    "    elif confidence > 70:\n",
    "        print(\"üëç Fairly confident prediction.\")\n",
    "    else:\n",
    "        print(\"ü§î Low confidence - the review might be ambiguous.\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "We've successfully built a sentiment analyzer for movie reviews that:\n",
    "- Achieves ~85% accuracy on test data\n",
    "- Can classify reviews as positive or negative with confidence scores\n",
    "- Uses TF-IDF for feature extraction\n",
    "- Compares Naive Bayes and Logistic Regression models\n",
    "\n",
    "Feel free to experiment with different preprocessing techniques, feature extraction methods, or models to improve the performance!\n",
    "\n",
    "---\n",
    "Made with ‚ù§Ô∏è by Shams Rupak"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
